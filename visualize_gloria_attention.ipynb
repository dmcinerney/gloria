{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gloria\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gloria import builder, utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from mimic_data import ImaGenomeDataModule, MimicCxrFiler, ImaGenomeFiler, normalize\n",
    "import os\n",
    "import cv2\n",
    "from torch import nn\n",
    "from jupyter_innotater import *\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "# def normalize(x):\n",
    "#     return x\n",
    "\n",
    "def process_img(model, imgs, device):\n",
    "\n",
    "    transform = builder.build_transformation(model.cfg, split=\"test\")\n",
    "\n",
    "    all_imgs = []\n",
    "    for x in imgs:\n",
    "\n",
    "        # tranform images\n",
    "        x = np.array((normalize(x) * 2 - 1) * 255, dtype=np.uint8)\n",
    "        x = model._resize_img(x, model.cfg.data.image.imsize)\n",
    "        img = Image.fromarray(x).convert(\"RGB\")\n",
    "        img = transform(img)\n",
    "        all_imgs.append(torch.tensor(img))\n",
    "\n",
    "    all_imgs = torch.stack(all_imgs).to(device)\n",
    "\n",
    "    return all_imgs\n",
    "\n",
    "\n",
    "def bbox_to_mask(bbox, image_shape):\n",
    "    image1 = torch.zeros(image_shape, dtype=torch.bool)\n",
    "    image1[bbox[1]:, bbox[0]:] = 1\n",
    "    image2 = torch.zeros(image_shape, dtype=torch.bool)\n",
    "    image2[:bbox[3] + 1, :bbox[2] + 1] = 1\n",
    "    box_mask = image1 & image2\n",
    "    return box_mask\n",
    "\n",
    "\n",
    "def mask_to_bbox(box_mask):\n",
    "    if box_mask.sum() == 0:\n",
    "        return [-1, -1, -1, -1]\n",
    "    indices0 = torch.arange(box_mask.shape[0])\n",
    "    indices1 = torch.arange(box_mask.shape[1])\n",
    "    indices0 = indices0.unsqueeze(1).expand(*box_mask.shape)[box_mask]\n",
    "    indices1 = indices1.unsqueeze(0).expand(*box_mask.shape)[box_mask]\n",
    "    return [indices1.min().item(), indices0.min().item(), indices1.max().item(), indices0.max().item()]\n",
    "\n",
    "\n",
    "def process_bboxes(model, image_shape, bboxes):\n",
    "    new_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        box_mask = bbox_to_mask(bbox, image_shape)\n",
    "        new_box_mask = process_img(model, [box_mask], 'cpu')\n",
    "        new_box_mask = new_box_mask > 0\n",
    "        coords = mask_to_bbox(new_box_mask[0, 0])\n",
    "        new_bboxes.append(coords)\n",
    "    return new_bboxes\n",
    "\n",
    "\n",
    "def get_batch(model, texts, imgs, device):\n",
    "    batch = model.process_text(texts, device)\n",
    "    batch['imgs'] = process_img(model, imgs, device)\n",
    "    return batch\n",
    "\n",
    "\n",
    "def plot_attn_maps(attn_maps, imgs, sents, epoch_idx=0, batch_idx=0, nvis=1):\n",
    "\n",
    "    img_set, _ = utils.build_attention_images(\n",
    "        imgs,\n",
    "        attn_maps,\n",
    "#         max_word_num=self.cfg.data.text.word_num,\n",
    "        nvis=nvis,\n",
    "#         rand_vis=self.cfg.train.rand_vis,\n",
    "        sentences=sents,\n",
    "    )\n",
    "\n",
    "    if img_set is not None:\n",
    "        return Image.fromarray(img_set)\n",
    "\n",
    "\n",
    "def plot_attention_from_raw(images, reports, model, filename='attention.jpg'):\n",
    "    reports = [report[report.index('FINDINGS:'):] if 'FINDINGS:' in report else report for report in reports]\n",
    "    batch_size = len(images)\n",
    "    batch = get_batch(model, reports, images, 'cuda')\n",
    "    img_emb_l, img_emb_g, text_emb_l, text_emb_g, sents = model(batch)\n",
    "    attn_maps = model.get_attn_maps(img_emb_l, text_emb_l, sents)\n",
    "    im = plot_attn_maps(attn_maps, batch['imgs'].cpu(), sents, nvis=batch_size)\n",
    "    im.save(filename)\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(image, bboxes, color=(255, 0, 0)):\n",
    "    thickness = image.shape[0] // 100\n",
    "    for bbox in bboxes:\n",
    "        image = cv2.rectangle(image, bbox[:2], bbox[2:], color, thickness)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_bounding_boxes_mask(image_shape, bboxes):\n",
    "    image = np.zeros(image_shape)\n",
    "    image = draw_bounding_boxes(image, bboxes, color=1)\n",
    "    return image == 1\n",
    "\n",
    "\n",
    "def show_attention_from_raw(batch, model):\n",
    "    batch_size = len(batch['imgs'])\n",
    "    img_emb_l, img_emb_g, text_emb_l, text_emb_g, sents = model(batch)\n",
    "    attn_maps = model.get_attn_maps(img_emb_l, text_emb_l, sents)\n",
    "    im = attn_maps[0][0].sum(0).cpu().detach().numpy()\n",
    "    return im\n",
    "\n",
    "\n",
    "def to_rgb(image):\n",
    "    return np.array((normalize(image) * 255).int().unsqueeze(-1).expand(*image.shape, 3).cpu(), dtype=np.uint8)\n",
    "\n",
    "\n",
    "def process_instance(instance, model, plot=True):\n",
    "    patient_id = next(iter(instance.keys()))\n",
    "    study_id = next(iter(instance[patient_id].keys()))\n",
    "    instance = instance[patient_id][study_id]\n",
    "    dicom_id = next(iter(instance['images'].keys()))\n",
    "    image = instance['images'][dicom_id]\n",
    "    sent_ids = sorted(list(instance['objects'][dicom_id]['sent_to_bboxes'].keys()))\n",
    "    sents, bbox_names, new_bboxes, attentions, images, labels, contexts = [], [], [], [], [], [], []\n",
    "    for sent_id in sent_ids:\n",
    "        sent_info = instance['objects'][dicom_id]['sent_to_bboxes'][sent_id]\n",
    "        sents.append(sent_info['sentence'])\n",
    "        bbox_names.append(sent_info['bboxes'])\n",
    "        sent_bboxes = sent_info['coords_original']\n",
    "        labels.append(sent_info['labels'])\n",
    "        contexts.append(sent_info['contexts'])\n",
    "        sent_images = []\n",
    "        if plot:\n",
    "            print('sentence:', sents[-1])\n",
    "            print('bbox names:', bbox_names[-1])\n",
    "            print('labels:', labels[-1])\n",
    "            print('context:', contexts[-1])\n",
    "            fig, axes = plt.subplots(1, 3)\n",
    "        image1 = draw_bounding_boxes(to_rgb(image), sent_bboxes)\n",
    "        sent_images.append(image1)\n",
    "        if plot:\n",
    "            axes[0].imshow(image1)\n",
    "        batch = get_batch(model, [sents[-1]], [image], 'cuda')\n",
    "        new_sent_bboxes = process_bboxes(model, image.shape, sent_bboxes)\n",
    "        new_bboxes.append(new_sent_bboxes)\n",
    "        image2 = batch['imgs'][0, 0]\n",
    "        image2 = draw_bounding_boxes(to_rgb(image2), new_sent_bboxes)\n",
    "        sent_images.append(image2)\n",
    "        if plot:\n",
    "            axes[1].imshow(image2)\n",
    "        attn = torch.tensor(show_attention_from_raw(batch, model))\n",
    "        attn = attn.reshape(1, 1, *attn.shape)\n",
    "        new_attn = nn.Upsample(size=image2.shape[:2], mode=\"bilinear\")(attn)\n",
    "        attentions.append(new_attn[0, 0])\n",
    "        new_attn = draw_bounding_boxes(to_rgb(new_attn[0, 0]), new_sent_bboxes)\n",
    "        sent_images.append(new_attn)\n",
    "        if plot:\n",
    "            axes[2].imshow(new_attn)\n",
    "            plt.show()\n",
    "        images.append(sent_images)\n",
    "    return dict(\n",
    "        bbox_names=bbox_names,\n",
    "        new_bboxes=new_bboxes,\n",
    "        attentions=attentions,\n",
    "        images=images,\n",
    "        sents=sents,\n",
    "        sent_ids=sent_ids,\n",
    "        labels=labels,\n",
    "        contexts=contexts,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_and_save_instance_results(path, dataset, model, num_examples=None):\n",
    "    if num_examples is None:\n",
    "        num_examples = len(model)\n",
    "    if not os.path.exists(os.path.join(path, 'sentences.csv')):\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        if not os.path.exists(os.path.join(path, 'bbox_images0')):\n",
    "            os.mkdir(os.path.join(path, 'bbox_images0'))\n",
    "        if not os.path.exists(os.path.join(path, 'bbox_images1')):\n",
    "            os.mkdir(os.path.join(path, 'bbox_images1'))\n",
    "        if not os.path.exists(os.path.join(path, 'bbox_images2')):\n",
    "            os.mkdir(os.path.join(path, 'bbox_images2'))\n",
    "        if not os.path.exists(os.path.join(path, 'attentions')):\n",
    "            os.mkdir(os.path.join(path, 'attentions'))\n",
    "        info = []\n",
    "        for i in tqdm(range(num_examples), total=num_examples):\n",
    "            instance = dataset[i]\n",
    "            patient_id = next(iter(instance.keys()))\n",
    "            study_id = next(iter(instance[patient_id].keys()))\n",
    "            dicom_id = next(iter(instance[patient_id][study_id]['images'].keys()))\n",
    "            outs = process_instance(instance, model, plot=False)\n",
    "            for sent_id, sent, bbox_names, bboxes, sent_labels, sent_contexts, sent_images, attention in zip(\n",
    "                    outs['sent_ids'], outs['sents'], outs['bbox_names'], outs['new_bboxes'],\n",
    "                    outs['labels'], outs['contexts'], outs['images'], outs['attentions']):\n",
    "                dicom_sent_id = 'dicom_%s_sent_%s' % (dicom_id, sent_id)\n",
    "                info.append([\n",
    "                    patient_id,\n",
    "                    study_id,\n",
    "                    dicom_id,\n",
    "                    sent_id,\n",
    "                    dicom_sent_id,\n",
    "                    sent,\n",
    "                    str(bbox_names),\n",
    "                    str(bboxes),\n",
    "                    str(sent_labels),\n",
    "                    str(sent_contexts),\n",
    "                ])\n",
    "                Image.fromarray(sent_images[0]).save(\n",
    "                    os.path.join(path, 'bbox_images0', dicom_sent_id + '.jpg'))\n",
    "                Image.fromarray(sent_images[1]).save(\n",
    "                    os.path.join(path, 'bbox_images1', dicom_sent_id + '.jpg'))\n",
    "                Image.fromarray(sent_images[2]).save(\n",
    "                    os.path.join(path, 'bbox_images2', dicom_sent_id + '.jpg'))\n",
    "                np.save(os.path.join(path, 'attentions', dicom_sent_id + '.np'), attention)\n",
    "        df = pd.DataFrame(info, columns=[\n",
    "            'patient_id',\n",
    "            'study_id',\n",
    "            'dicom_id',\n",
    "            'sent_id',\n",
    "            'dicom_sent_id',\n",
    "            'sentence',\n",
    "            'bbox_names',\n",
    "            'bboxes',\n",
    "            'sent_labels',\n",
    "            'sent_contexts',\n",
    "        ])\n",
    "        df.to_csv(os.path.join(path, 'sentences.csv'))\n",
    "    else:\n",
    "        df = pd.read_csv(os.path.join(path, 'sentences.csv'))\n",
    "    return df\n",
    "\n",
    "\n",
    "def annotate(path, dataset, model, num_examples=None, labels=None):\n",
    "    df = get_and_save_instance_results(path, dataset, model, num_examples=num_examples)\n",
    "    if labels is None:\n",
    "        labels = [0] * len(df)\n",
    "    sentences = df.sentence.tolist()\n",
    "    entities = []\n",
    "    for i, row in df.iterrows():\n",
    "        entities.append('')\n",
    "        ent_to_bbox = {}\n",
    "        for label, context, bbox in zip(eval(row.sent_labels), eval(row.sent_contexts), eval(row.bbox_names)):\n",
    "            if (label, context) not in ent_to_bbox.keys():\n",
    "                ent_to_bbox[(label, context)] = set()\n",
    "            ent_to_bbox[(label, context)].add(bbox)\n",
    "        for k, v in ent_to_bbox.items():\n",
    "            entities[-1] += str(k) + ': ' + str(v) + '\\n'\n",
    "    files = [name + '.jpg' for name in df.dicom_sent_id.tolist()]\n",
    "    classes = ['0 - Unselected', '1 - Positive', '2 - Ambiguous', '3 - Negative']\n",
    "    return Innotater(\n",
    "        [\n",
    "            TextInnotation(sentences),\n",
    "            TextInnotation(entities),\n",
    "    #         ImageInnotation(files, path=os.path.join(path, 'bbox_images0'), width=10, height=10),\n",
    "            ImageInnotation(files, path=os.path.join(path, 'bbox_images1'), width=200, height=200),\n",
    "            ImageInnotation(files, path=os.path.join(path, 'bbox_images2'), width=200, height=200),\n",
    "        ],\n",
    "        MultiClassInnotation(labels, classes=classes),\n",
    "    ), labels\n",
    "\n",
    "\n",
    "def compute_auroc(sent_attention, sent_bboxes):\n",
    "    label_segmentation = torch.zeros_like(sent_attention, dtype=torch.bool)\n",
    "    for bbox in sent_bboxes:\n",
    "        label_segmentation = label_segmentation | bbox_to_mask(bbox, sent_attention.shape)\n",
    "    if label_segmentation.sum() > 0:\n",
    "        return AUROC()(sent_attention.reshape(-1), label_segmentation.reshape(-1).long())\n",
    "\n",
    "\n",
    "def compute_metrics(path, dataset, model, num_examples=None):\n",
    "    df = get_and_save_instance_results(path, dataset, model, num_examples=num_examples)\n",
    "    aurocs = []\n",
    "    for i, row in df.iterrows():\n",
    "        sent_attention = np.load(row.dicom_sent_id + '.jpg')\n",
    "        auroc = compute_auroc(sent_attention, row.bboxes)\n",
    "        if auroc is not None:\n",
    "            aurocs.append(auroc)\n",
    "    print(sum(aurocs) / len(aurocs))\n",
    "    with open('gold_scores.pkl', 'wb') as f:\n",
    "        pkl.dump({'aurocs': aurocs}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcinerney.de/Documents/projects/gloria/mimic_data.py:765: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dicom_ids = set(gold_object_attribute_with_coordinates_df.image_id.str.replace('.dcm', ''))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3821/3821 [00:00<00:00, 88915.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gold (500):\n",
      "\n",
      "Filter dicoms so view position is '['PA', 'AP']':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 98517.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save dicoms to pytorch files:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 37483.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save reports:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 41610.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mimic_cxr_filer = MimicCxrFiler(\n",
    "    download_directory='/scratch/mcinerney.de/mimic-cxr', physio_username='dmcinerney')\n",
    "imagenome_filer = ImaGenomeFiler(\n",
    "    download_directory='/scratch/mcinerney.de/imagenome', physio_username='dmcinerney',\n",
    "    physio_password=mimic_cxr_filer.password)\n",
    "\n",
    "dm = ImaGenomeDataModule(\n",
    "    mimic_cxr_filer, imagenome_filer, batch_size=8, num_workers=5, collate_fn=None,\n",
    "    get_images=True, get_reports=True, force=False, parallel=False,\n",
    "    num_preprocessing_workers=os.cpu_count(), chunksize=1, split_slices='gold', gold_test=False)\n",
    "\n",
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>dicom_id</th>\n",
       "      <th>path</th>\n",
       "      <th>ViewPosition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>10020740</td>\n",
       "      <td>55522869</td>\n",
       "      <td>27776756-1d9ef4fc-cd8dd0ca-1453072f-12c0f484</td>\n",
       "      <td>files/p10/p10020740/s55522869/27776756-1d9ef4f...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>10037020</td>\n",
       "      <td>58400371</td>\n",
       "      <td>76289ac1-3ef7c087-3e77810d-63462e2c-20c0364c</td>\n",
       "      <td>files/p10/p10037020/s58400371/76289ac1-3ef7c08...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>10063856</td>\n",
       "      <td>54814005</td>\n",
       "      <td>4bb710ab-ab7d4781-568bcd6e-5079d3e6-7fdb61b6</td>\n",
       "      <td>files/p10/p10063856/s54814005/4bb710ab-ab7d478...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>10098993</td>\n",
       "      <td>52050071</td>\n",
       "      <td>01e55956-89f296bb-002ac02d-e08ee2a9-832f1cff</td>\n",
       "      <td>files/p10/p10098993/s52050071/01e55956-89f296b...</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>10104308</td>\n",
       "      <td>52433992</td>\n",
       "      <td>749d7548-73506c3c-c2d571b0-609dd2f9-746e60a7</td>\n",
       "      <td>files/p10/p10104308/s52433992/749d7548-73506c3...</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3800</td>\n",
       "      <td>19966115</td>\n",
       "      <td>59650514</td>\n",
       "      <td>198be438-16dc1b2c-e4d95d59-25e6b0a8-9e815c12</td>\n",
       "      <td>files/p19/p19966115/s59650514/198be438-16dc1b2...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3805</td>\n",
       "      <td>19969031</td>\n",
       "      <td>54877992</td>\n",
       "      <td>4e78a467-5eede0ee-476cb29e-af0db15d-69c4465c</td>\n",
       "      <td>files/p19/p19969031/s54877992/4e78a467-5eede0e...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3807</td>\n",
       "      <td>19986230</td>\n",
       "      <td>50379095</td>\n",
       "      <td>27d2ca4c-93c1fe0c-3104a1a6-1f1118dd-14ae6eac</td>\n",
       "      <td>files/p19/p19986230/s50379095/27d2ca4c-93c1fe0...</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>3814</td>\n",
       "      <td>19989918</td>\n",
       "      <td>53487857</td>\n",
       "      <td>5da30295-f1eadf3e-001ddb71-3b07c00c-2883f874</td>\n",
       "      <td>files/p19/p19989918/s53487857/5da30295-f1eadf3...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>3819</td>\n",
       "      <td>19998497</td>\n",
       "      <td>50311574</td>\n",
       "      <td>53a6e508-c64868f0-cea054db-f7610b25-ef5fb32a</td>\n",
       "      <td>files/p19/p19998497/s50311574/53a6e508-c64868f...</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  subject_id  study_id  \\\n",
       "0             8    10020740  55522869   \n",
       "1            31    10037020  58400371   \n",
       "2            32    10063856  54814005   \n",
       "3            39    10098993  52050071   \n",
       "4            48    10104308  52433992   \n",
       "..          ...         ...       ...   \n",
       "495        3800    19966115  59650514   \n",
       "496        3805    19969031  54877992   \n",
       "497        3807    19986230  50379095   \n",
       "498        3814    19989918  53487857   \n",
       "499        3819    19998497  50311574   \n",
       "\n",
       "                                         dicom_id  \\\n",
       "0    27776756-1d9ef4fc-cd8dd0ca-1453072f-12c0f484   \n",
       "1    76289ac1-3ef7c087-3e77810d-63462e2c-20c0364c   \n",
       "2    4bb710ab-ab7d4781-568bcd6e-5079d3e6-7fdb61b6   \n",
       "3    01e55956-89f296bb-002ac02d-e08ee2a9-832f1cff   \n",
       "4    749d7548-73506c3c-c2d571b0-609dd2f9-746e60a7   \n",
       "..                                            ...   \n",
       "495  198be438-16dc1b2c-e4d95d59-25e6b0a8-9e815c12   \n",
       "496  4e78a467-5eede0ee-476cb29e-af0db15d-69c4465c   \n",
       "497  27d2ca4c-93c1fe0c-3104a1a6-1f1118dd-14ae6eac   \n",
       "498  5da30295-f1eadf3e-001ddb71-3b07c00c-2883f874   \n",
       "499  53a6e508-c64868f0-cea054db-f7610b25-ef5fb32a   \n",
       "\n",
       "                                                  path ViewPosition  \n",
       "0    files/p10/p10020740/s55522869/27776756-1d9ef4f...           AP  \n",
       "1    files/p10/p10037020/s58400371/76289ac1-3ef7c08...           AP  \n",
       "2    files/p10/p10063856/s54814005/4bb710ab-ab7d478...           AP  \n",
       "3    files/p10/p10098993/s52050071/01e55956-89f296b...           PA  \n",
       "4    files/p10/p10104308/s52433992/749d7548-73506c3...           PA  \n",
       "..                                                 ...          ...  \n",
       "495  files/p19/p19966115/s59650514/198be438-16dc1b2...           AP  \n",
       "496  files/p19/p19969031/s54877992/4e78a467-5eede0e...           AP  \n",
       "497  files/p19/p19986230/s50379095/27d2ca4c-93c1fe0...           PA  \n",
       "498  files/p19/p19989918/s53487857/5da30295-f1eadf3...           AP  \n",
       "499  files/p19/p19998497/s50311574/53a6e508-c64868f...           AP  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = dm.get_dataset('gold')\n",
    "gold.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLoRIA(\n",
       "  (text_encoder): BertEncoder(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (img_encoder): ImageEncoder(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (global_embedder): Linear(in_features=2048, out_features=768, bias=True)\n",
       "    (local_embedder): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "gloria_model = gloria.load_gloria(name='gloria_resnet18', device=device)\n",
    "gloria_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                          | 0/2 [00:00<?, ?it/s]/home/mcinerney.de/Documents/projects/gloria/mimic_data.py:657: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  object_rows = self.gold_objects_df[self.gold_objects_df.image_id.str.replace('.dcm', '') == dicom_id]\n",
      "/tmp/ipykernel_13185/2435797683.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  all_imgs.append(torch.tensor(img))\n",
      "/home/mcinerney.de/.conda/envs/gloria/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.43s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a227eeabf0c74e29a87f18cb6961d3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(Textarea(value='No acute cardiopulmonary abnormality.', disa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'annotations11'\n",
    "innotator, labels = annotate(path, gold, gloria_model, num_examples=2)\n",
    "innotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out for safety\n",
    "# with open(os.path.join(path, 'labels.pkl'), 'wb') as f:\n",
    "#     pkl.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'annotations'\n",
    "with open(os.path.join(path, 'labels.pkl'), 'rb') as f:\n",
    "    labels = pkl.load(f)\n",
    "innotator, labels = annotate(path, gold, gloria_model, num_examples=100, labels=labels)\n",
    "innotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(labels) != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(labels) == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(labels) == 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(labels) == 3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "59 / 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "35 / 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7 / 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
