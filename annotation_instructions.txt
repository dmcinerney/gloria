instructions

### Instructions

Our aim here is to collect judgements (*annotations*) concerning the interpretability and possible usefulness of alignments between text snippets and image regions induced by neural network models.
More specifically, we will ask you to evaluate “heatmaps” output by different unsupervised (or minimally supervised) models which attempt to align natural language (sentences) and image regions (within accompanying chest X-rays).
We ask three specific questions to asses these heatmaps; each question is 5-way multiple choice, and each of the answers are described below.
In each round of annotation collection, we aim to collect annotations for multiple models with respect to a shared set of text snippets.
That is, for each image, we ask for multiple assessments (across models) for the quality of alignments performed for a particular sentence.
You will not be told which model generated which "heatmaps", and model aliases are randomly selected for every instance.

#### Prompts

You can choose the natural language sentences fed to the model—which we refer to as “prompts”— by either selecting a sentence from the list of sentences in the associated radiology report, or by writing your own “custom” prompt.
We ask you to complete one round of annotations for report sentences, followed by one round in which you evaluate the alignments generated by the model for custom prompts (i.e., text you enter).
For the report sentences round, we ask you to select one sentence that you think is interesting from the list of report sentences (prior to looking at any heatmaps).
You will then annotate or judge the alignments induced by all models for this particular sentence.
For custom annotations, we ask you to write one sentence to use as a prompt that talks about a feature of the image, and then annotate all models on this sentence.

#### Annotations

Bellow we list the questions and what each of the possible answers would mean.
1. **The heatmap includes what percentage of the region of interest from the prompt?**
    * 0-20 -- The heatmap is focused on entirely the wrong part of the image, does not highlight any part of the image strongly, or has very minimal intensity on the region of interest.
    * 20-40
    * 40-60 -- The heatmap comes close to covering the region of interest, or does cover the region of interest but with not too much intensity.
    * 60-80
    * 80-100 -- The prompt refers to a region that is within a high-intensity part of the heatmap.
2. **What percentage of the heatmap represents an area of interest?**
    * 0-20 -- This heatmap is all over the place or highlights a large portion of the image.
    * 20-40
    * 40-60 -- The focus includes the relevant region(s) but also other irrelevant regions (either adjacent or elsewhere in the image).
    * 60-80
    * 80-100 -- The heatmap is very targeted to only the parts of the image most relevant to the prompt.
3. **Rate how intuitive the heatmap is on a scale from 1-5 (1 being the worst, 5 being the best).**
    * 1 -- The heatmap is completely unhelpful, counterintuitive, or misleading.
    * 2 -- The heatmap might have something in common with an intuitive one, but very little.
    * 3 -- The heatmap does show a region of tiniest, but has some stray parts or does not catch all relevant regions.
    * 4 -- The heatmap is reasonably intuitive and contains mostly (though not exclusively) the regions I would expect.
    * 5 -- The heatmap is almost exactly what you might draw to represent the region of interest.

#### Important Details

**Ground truth bounding boxes**: You have the ability to see *ground truth* bounding boxes from the dataset associated with the particular sentence you have selected from the report; these were manually drawn to match the corresponding sentence. We suggest that you use these bounding boxes when annotating the heatmaps associated with the report sentences. No such bounding boxes are available for the custom prompts that you will author.

**Adjusting saliency strength**: You may need to adjust the strength of the visibility of the "saliency" (i.e., the "highlighted" pattern induced by the model), depending on the model or the instance so that you can properly see the heatmap before annotating it. This just makes the highlight more or less intense.

**Examples**: Below we provide some examples of image-text-heatmap examples and our suggested annotations for these so you can get a better idea what we are looking for.
-
yes_yes_yes

UNFINISHED/UNCONFIRMED
(1) 5, (2) 5, (3) 5
-
no_no_yes

UNFINISHED/UNCONFIRMED
(1) 1, (2) 5, (3) 5
-
partially_partially_partially

UNFINISHED/UNCONFIRMED
(1) 3, (2) 3, (3) 3
-
no_partially_partially

UNFINISHED/UNCONFIRMED
(1) 1, (2) 3, (3) 3
