instructions

### Instructions

Our aim here is to collect judgements (*annotations*) concerning the interpretability and possible usefulness of alignments between text snippets and image regions induced by neural network models.
More specifically, we will ask you to evaluate “heatmaps” output by different unsupervised (or minimally supervised) models which attempt to align natural language (sentences) and image regions (within accompanying chest X-rays). We ask three specific questions to asses these heatmaps; each question can have an answer of either “no,” “partially,” or “yes.”
In each round of annotation collection, we aim to collect annotations for multiple models with respect to a shared set of text snippets. That is, for each image, we ask for multiple assessments (across models) for the quality of alignments performed for a particular sentence. You will not be told which model generated which "heatmaps", and model aliases are randomly selected for every instance.

#### Prompts

You can choose the natural language sentences fed to the model—which we refer to as “prompts”— by either selecting a sentence from the list of sentences in the associated radiology report, or by writing your own “custom” prompt.
We ask you to complete one round of annotations for report sentences, followed by one round in which you evaluate the alignments generated by the model for custom prompts (i.e., text you enter). For the report sentences round, we ask you to select one sentence that you think is interesting from the list of report sentences (prior to looking at any heatmaps). You will then annotate or judge the alignments induced by all models for this particular sentence.
For custom annotations, we ask you to write one sentence to use as a prompt that talks about a feature of the image, and then annotate all models on this sentence.

#### Annotations

Bellow we list the questions and what each of the possible answers would mean.
1. **Is the region of interest from the prompt in the heatmap?**
    * “yes” -- The prompt refers to a region that is within a high-intensity part of the heatmap.
    * “partially” -- The heatmap comes close to covering the region of interest, or does cover the region of interest but with not too much intensity.
    * “no” -- The heatmap is focused on entirely the wrong part of the image, does not highlight any part of the image strongly, or has very minimal intensity on the region of interest.
2. **Does the heatmap contain irrelevant regions?**
    * “yes” -- This heatmap is all over the place or highlights a large portion of the image.
    * “partially” -- The focus includes the relevant region(s) but also other irrelevant regions (either adjacent or elsewhere in the image).
    * “no” -- The heatmap is very targeted to only the parts of the image most relevant to the prompt.
3. **Is this heatmap intuitive?**
    * “yes” -- If you were to draw your own heatmap of the regions of interest, it would look very similar to the heatmap displayed.
    * “partially” -- The heatmap seems plausable, but it is a bit vague or not too similar to what you would draw.
    * “no” -- It is totally incorrect or does not give any insight into where to look when determining to what the text is referring.

#### Important Details

**Ground truth bounding boxes**: You have the ability to see *ground truth* bounding boxes from the dataset associated with the particular sentence you have selected from the report; these were manually drawn to match the corresponding sentence. We suggest that you use these bounding boxes when annotating the heatmaps associated with the report sentences. No such bounding boxes are available for the custom prompts that you will author.

**Adjusting saliency strength**: You may need to adjust the strength of the visibility of the "saliency" (i.e., the "highlighted" pattern induced by the model), depending on the model or the instance so that you can properly see the heatmap before annotating it. This just makes the highlight more or less intense.

**Examples**: Below we provide some examples of image-text-heatmap examples and our suggested annotations for these so you can get a better idea what we are looking for.
-
yes_yes_yes

(1) yes, (2) yes, (3) yes
-
no_no_yes

(1) no, (2) no, (3) yes
-
partially_partially_partially

(1) partially, (2) partially, (3) partially
-
no_partially_partially

(1) no, (2) partially, (3) partially
