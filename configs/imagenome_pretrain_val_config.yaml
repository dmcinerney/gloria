experiment_name: 'gloria_pretrain'
phase: 'pretrain'

lightning:
    trainer:
        gpus: '0'
        max_epochs: 50
        distributed_backend: 'dp'
        gradient_clip_val: 0.25
        lr: 0.00005
#        precision: 16
        reload_dataloaders_every_n_epochs: 1
        limit_train_batches: 0.2
        limit_val_batches: 0.05
        check_val_every_n_epoch: 1
    checkpoint_callback:
        monitor: 'val_loss'
        dirpath: '/scratch/mcinerney.de/gloria_outputs6/ckpt'
        save_last: true 
        mode: min
        save_top_k: 10
    early_stopping_callback:
        monitor: 'val_loss'
        min_delta: 0.00
        patience: 10
        verbose: false
        mode: 'min'
    logger:
        logger_type: 'WandbLogger'
        save_dir: '/scratch/mcinerney.de/gloria_outputs4/'
        project: 'gloria_v6'
    evaluate_localization:
        eval_attn_overlay_mode: 'upsample'
        plot_attn_overlay_mode: 'upsample'
        log_train_every: 100
        val_save_full_data: true
#    weight_instances_by_localization:
#        weight_mode: 'no_attn_score'
#        temp: 2.0

model:
#    checkpoint: './pretrained/chexpert_resnet18.ckpt'
    checkpoint: './pretrained/chexpert_resnet50.ckpt'
#    checkpoint: './pretrained/retrained_abnormal_best_epoch10.ckpt'
#    checkpoint: './pretrained/retrained_abnormal_last_epoch20.ckpt'
#    checkpoint: './pretrained/retrained_best_epoch6.ckpt'
#    checkpoint: './pretrained/retrained_kl_best_epoch11.ckpt'
#    checkpoint: './pretrained/retrained_kl_last_epoch19.ckpt'
#    checkpoint: './pretrained/retrained_last_epoch16.ckpt'
#    checkpoint: './pretrained/retrained_pos_last_epoch27.ckpt'
#    checkpoint: './pretrained/retrained_randsent_last_epoch10.ckpt'
#    checkpoint: './pretrained/retrained_transformer_last_epoch19.ckpt'
    gloria:
        local_loss_weight: 1.0
        global_loss_weight: 1.0
        temp1: 4.0
        temp2: 5.0
        temp3: 10.0
        no_attn_vec: false
#         no_attn_loss_weight: 1.0
#         attention_divergence_loss_weight: 1.0
#         sparse_attn_weight: 1.0
    vision:
        model_name: 'resnet_50'
        freeze_cnn: false
        pretrained: true
    text:
        bert_type: "emilyalsentzer/Bio_ClinicalBERT"
        last_n_layers: 4
        aggregate_method: 'sum'
        norm: false
        embedding_dim: 768
        freeze_bert: false
        agg_tokens: true
#    image_position_embeddings:
#        num: 19
#    image_transformer:
#        num_heads: 12
#        num_layers: 1

data:
    dataset: imagenome
    text: 
        word_num: 97
        captions_per_image: 5
        full_report: true
    image:
        imsize: 256
    split_slices: ''
    parallel: true
    get_physio_creds: false
    mimic_cxr_download_directory: '/scratch/mcinerney.de/mimic-cxr'
    imagenome_download_directory: '/scratch/mcinerney.de/imagenome'
    gold_test: true
    randomize_reports: false
    group_by: 'sentence'
#    randomize_objects_mode: 'shuffle_bboxes_sentences'
#    randomize_objects_mode: 'random_bboxes'
#    randomize_objects_mode: 'random_sentences'
    swap_left_right: false
    generate_sent: false
    swap_conditions: false
#     mask_mode: 'clinical'
    mask_prob: .5

transforms: 
    norm: 'half'
    random_crop:
        crop_size: 224

train:
    update_interval: 1000
    batch_size: 48
    num_workers: 12
    nvis: 8
    rand_vis: false 
    optimizer: 
        name: 'Adam'
        weight_decay: 1e-6
    scheduler: 
        name: 'plateau'
        monitor: 'val_loss'
        inerval: 'epoch'
        frequency: 1

base_output_dir: '/scratch/mcinerney.de/gloria_outputs6/output'
